{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgnY5aDZUSsw",
        "outputId": "76863184-8970-45bb-8f2f-0f190bfb9f5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bibliotecas importadas com sucesso.\n",
            "Funções auxiliares definidas.\n",
            "\n",
            "Dataset de Classificação (PowerSupply) carregado: 29928 linhas, 3 colunas\n",
            "Dataset de Regressão (CPU) carregado: 209 linhas, 7 colunas\n",
            "Pré-processamento configurado para ambos os datasets.\n",
            "Modelos definidos.\n",
            "\n",
            "--- Processando Tabela A: Classificação com Hold-out (65/35) ---\n",
            "  - KNN: Concluído\n",
            "  - Decision Tree: Concluído\n",
            "  - Naive Bayes: Concluído\n",
            "  - MLP: Concluído\n",
            "  - SVM: Concluído\n",
            "  - Ensemble (somatória): Concluído\n",
            "  - Random Forest: Concluído\n",
            "  - Bagging: Concluído\n",
            "  - Boosting: Concluído\n",
            "  - Stacking: Concluído\n",
            "  - Blending: Concluído\n",
            "  - Adicional: Concluído\n",
            "\n",
            "--- Processando Tabela B: Classificação com Validação Cruzada (5 folds) ---\n",
            "  - KNN: Concluído\n",
            "  - Decision Tree: Concluído\n",
            "  - Naive Bayes: Concluído\n",
            "  - MLP: Concluído\n",
            "  - SVM: Concluído\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "# 1. IMPORTAÇÕES E CONFIGURAÇÕES INICIAIS\n",
        "#\n",
        "# Importo bibliotecas principais para manipulação de dados e ML\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.io import arff\n",
        "import warnings\n",
        "\n",
        "# Modelos de classificação e regressão exigidos pelo PjBL\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier, RandomForestRegressor,\n",
        "    BaggingClassifier, BaggingRegressor,\n",
        "    AdaBoostClassifier, AdaBoostRegressor,\n",
        "    StackingClassifier, StackingRegressor,\n",
        "    VotingClassifier, VotingRegressor,\n",
        "    GradientBoostingClassifier, GradientBoostingRegressor\n",
        ")\n",
        "\n",
        "# Ferramentas de pré-processamento e criação de pipelines\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Ferramentas para avaliação de modelos (hold-out e k-fold)\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_validate\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, f1_score, precision_score, recall_score,\n",
        "    confusion_matrix, r2_score, mean_squared_error, mean_absolute_error,\n",
        "    make_scorer\n",
        ")\n",
        "\n",
        "# Ignoro avisos que não interferem nos resultados (pra deixar a saída limpa)\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
        "\n",
        "print(\"Bibliotecas importadas com sucesso.\")\n",
        "\n",
        "#\n",
        "# 2. FUNÇÕES AUXILIARES\n",
        "#\n",
        "\n",
        "def load_arff_to_df(path):\n",
        "    \"\"\"Carrega arquivo .arff e converte em DataFrame.\"\"\"\n",
        "    # Função compatível com datasets do WEKA/MOA\n",
        "    try:\n",
        "        data, meta = arff.loadarff(path)\n",
        "        df = pd.DataFrame(data)\n",
        "        # Decodifica strings (os ARFF vêm com bytes)\n",
        "        for col in df.select_dtypes([np.object_]).columns:\n",
        "            df[col] = df[col].str.decode('utf-8')\n",
        "        return df\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Erro: Arquivo '{path}' não encontrado.\")\n",
        "        print(\"Verifique o diretório do script.\")\n",
        "        return None\n",
        "\n",
        "def specificity_score(y_true, y_pred):\n",
        "    \"\"\"Calcula especificidade = TN / (TN + FP).\"\"\"\n",
        "    # sklearn não possui essa métrica, então implementei manualmente\n",
        "    if len(np.unique(y_true)) > 2:\n",
        "        # Versão multiclasse — calcula média por classe\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        fp = cm.sum(axis=0) - np.diag(cm)\n",
        "        fn = cm.sum(axis=1) - np.diag(cm)\n",
        "        tp = np.diag(cm)\n",
        "        tn = cm.sum() - (fp + fn + tp)\n",
        "        specificity = np.nan_to_num(tn / (tn + fp))\n",
        "        return np.mean(specificity)\n",
        "    else:\n",
        "        # Versão binária simples\n",
        "        cm_flat = confusion_matrix(y_true, y_pred).ravel()\n",
        "        if len(cm_flat) == 4:\n",
        "            tn, fp, fn, tp = cm_flat\n",
        "            return tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "        else:\n",
        "            return 0.0\n",
        "\n",
        "def get_classification_metrics(y_true, y_pred):\n",
        "    \"\"\"Calcula as métricas da parte de classificação.\"\"\"\n",
        "    # Retorna todas as colunas pedidas no PjBL (Tabela A e B)\n",
        "    return {\n",
        "        'Taxa de Acerto (%)': accuracy_score(y_true, y_pred) * 100,\n",
        "        'F1 (%)': f1_score(y_true, y_pred, average='macro') * 100,\n",
        "        'Precisão (%)': precision_score(y_true, y_pred, average='macro', zero_division=0) * 100,\n",
        "        'Sensibilidade (%)': recall_score(y_true, y_pred, average='macro') * 100,\n",
        "        'Especificidade (%)': specificity_score(y_true, y_pred) * 100\n",
        "    }\n",
        "\n",
        "def get_regression_metrics(y_true, y_pred):\n",
        "    \"\"\"Calcula as métricas da parte de regressão.\"\"\"\n",
        "    # Métricas pedidas nas Tabelas C e D\n",
        "    return {\n",
        "        'Coeficiente de Determinação (R2)': r2_score(y_true, y_pred),\n",
        "        'MSE': mean_squared_error(y_true, y_pred),\n",
        "        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
        "        'MAE': mean_absolute_error(y_true, y_pred)\n",
        "    }\n",
        "\n",
        "print(\"Funções auxiliares definidas.\")\n",
        "\n",
        "#\n",
        "# 3. PREPARAÇÃO DOS DADOS\n",
        "#\n",
        "\n",
        "# Carrego os datasets .arff (devem ser diferentes dos usados em aula)\n",
        "df_class = load_arff_to_df('powersupply.arff')\n",
        "df_reg = load_arff_to_df('cpu.arff')\n",
        "\n",
        "# --- Pré-processamento da Classificação ---\n",
        "if df_class is not None:\n",
        "    print(f\"\\nDataset de Classificação (PowerSupply) carregado: {df_class.shape[0]} linhas, {df_class.shape[1]} colunas\")\n",
        "    # Separo as features e o alvo\n",
        "    X_class = df_class.drop('class', axis=1).values\n",
        "    y_class_str = df_class['class'].values\n",
        "    # Transformo as classes textuais em números\n",
        "    le = LabelEncoder()\n",
        "    y_class = le.fit_transform(y_class_str)\n",
        "    # Normalizo os dados (muito importante pro MLP e SVM)\n",
        "    preprocessor_class = StandardScaler()\n",
        "\n",
        "# --- Pré-processamento da Regressão ---\n",
        "if df_reg is not None:\n",
        "    print(f\"Dataset de Regressão (CPU) carregado: {df_reg.shape[0]} linhas, {df_reg.shape[1]} colunas\")\n",
        "    target_reg = 'class'  # nome da variável dependente padrão em ARFF\n",
        "\n",
        "    if target_reg in df_reg.columns:\n",
        "        # Separo entradas e saídas\n",
        "        X_reg = df_reg.drop(columns=[target_reg])\n",
        "        y_reg = df_reg[target_reg].values\n",
        "        preprocessor_reg = StandardScaler()  # normalização simples\n",
        "        print(\"Pré-processamento configurado para ambos os datasets.\")\n",
        "    else:\n",
        "        print(f\"\\nERRO: O arquivo 'cpu.arff' não contém a coluna-alvo '{target_reg}'.\")\n",
        "        df_reg = None  # Evita erro adiante\n",
        "\n",
        "#\n",
        "# 4. DEFINIÇÃO DOS MODELOS\n",
        "#\n",
        "\n",
        "# Aqui defino todos os algoritmos exigidos nas tabelas do PjBL\n",
        "# A ideia é facilitar a execução automática de todos eles\n",
        "\n",
        "# --- Modelos de Classificação ---\n",
        "estimators_class = [('dt', DecisionTreeClassifier(random_state=42)), ('knn', KNeighborsClassifier())]\n",
        "voting_estimators_class = [('rf', RandomForestClassifier(random_state=42)), ('svm', SVC(probability=True, random_state=42)), ('nb', GaussianNB())]\n",
        "\n",
        "models_class = {\n",
        "    \"KNN\": KNeighborsClassifier(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"MLP\": MLPClassifier(max_iter=500, random_state=42),\n",
        "    \"SVM\": SVC(random_state=42),\n",
        "    \"Ensemble (somatória)\": VotingClassifier(estimators=voting_estimators_class, voting='soft'),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"Bagging\": BaggingClassifier(random_state=42),\n",
        "    \"Boosting\": AdaBoostClassifier(random_state=42),\n",
        "    \"Stacking\": StackingClassifier(estimators=estimators_class, final_estimator=RandomForestClassifier(random_state=42)),\n",
        "    \"Blending\": StackingClassifier(estimators=estimators_class, final_estimator=RandomForestClassifier(random_state=42), cv=2),\n",
        "    \"Adicional\": GradientBoostingClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "# --- Modelos de Regressão ---\n",
        "estimators_reg = [('dt', DecisionTreeRegressor(random_state=42)), ('knn', KNeighborsRegressor())]\n",
        "voting_estimators_reg = [('rf', RandomForestRegressor(random_state=42)), ('svr', SVR()), ('lr', LinearRegression())]\n",
        "\n",
        "models_reg = {\n",
        "    \"Regressão Linear\": LinearRegression(),\n",
        "    \"KNN\": KNeighborsRegressor(),\n",
        "    \"Árvore de Decisão\": DecisionTreeRegressor(random_state=42),\n",
        "    \"MLP\": MLPRegressor(max_iter=1000, random_state=42),\n",
        "    \"SVM\": SVR(),\n",
        "    \"Ensemble (Média)\": VotingRegressor(estimators=voting_estimators_reg),\n",
        "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
        "    \"Bagging\": BaggingRegressor(random_state=42),\n",
        "    \"Boosting\": AdaBoostRegressor(random_state=42),\n",
        "    \"Stacking\": StackingRegressor(estimators=estimators_reg, final_estimator=RandomForestRegressor(random_state=42)),\n",
        "    \"Blending\": StackingRegressor(estimators=estimators_reg, final_estimator=RandomForestRegressor(random_state=42), cv=2),\n",
        "    \"Adicional\": GradientBoostingRegressor(random_state=42)\n",
        "}\n",
        "print(\"Modelos definidos.\")\n",
        "\n",
        "#\n",
        "# 5. EXECUÇÃO DOS EXPERIMENTOS\n",
        "#\n",
        "\n",
        "# Aqui são geradas as 4 tabelas pedidas no PDF (A, B, C e D)\n",
        "# Cada bloco executa todos os modelos e armazena as métricas\n",
        "\n",
        "if df_class is not None:\n",
        "    # --- Tabela A: Classificação com Hold-out ---\n",
        "    print(\"\\n--- Processando Tabela A: Classificação com Hold-out (65/35) ---\")\n",
        "    results_A = []\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_class, y_class, test_size=0.35, random_state=42, stratify=y_class)\n",
        "    for name, model in models_class.items():\n",
        "        # Uso de pipeline pra aplicar normalização automaticamente\n",
        "        pipeline = Pipeline(steps=[('preprocessor', preprocessor_class), ('classifier', model)])\n",
        "        pipeline.fit(X_train, y_train)\n",
        "        y_pred = pipeline.predict(X_test)\n",
        "        # Calculo as métricas pedidas no PjBL\n",
        "        metrics = get_classification_metrics(y_test, y_pred)\n",
        "        metrics['Indutor'] = name\n",
        "        results_A.append(metrics)\n",
        "        print(f\"  - {name}: Concluído\")  # comentário rápido: indica progresso\n",
        "    df_results_A = pd.DataFrame(results_A)[['Indutor', 'Taxa de Acerto (%)', 'F1 (%)', 'Precisão (%)', 'Sensibilidade (%)', 'Especificidade (%)']]\n",
        "\n",
        "    # --- Tabela B: Classificação com Validação Cruzada (5 folds) ---\n",
        "    print(\"\\n--- Processando Tabela B: Classificação com Validação Cruzada (5 folds) ---\")\n",
        "    results_B = []\n",
        "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    scoring_class = {\n",
        "        'accuracy': 'accuracy',\n",
        "        'f1_macro': 'f1_macro',\n",
        "        'precision_macro': 'precision_macro',\n",
        "        'recall_macro': 'recall_macro',\n",
        "        'specificity': make_scorer(specificity_score)\n",
        "    }\n",
        "    for name, model in models_class.items():\n",
        "        pipeline = Pipeline(steps=[('preprocessor', preprocessor_class), ('classifier', model)])\n",
        "        scores = cross_validate(pipeline, X_class, y_class, cv=kfold, scoring=scoring_class)\n",
        "        results_B.append({\n",
        "            'Indutor': name,\n",
        "            'Taxa de Acerto (%)': scores['test_accuracy'].mean() * 100,\n",
        "            'F1 (%)': scores['test_f1_macro'].mean() * 100,\n",
        "            'Precisão (%)': scores['test_precision_macro'].mean() * 100,\n",
        "            'Sensibilidade (%)': scores['test_recall_macro'].mean() * 100,\n",
        "            'Especificidade (%)': scores['test_specificity'].mean() * 100\n",
        "        })\n",
        "        print(f\"  - {name}: Concluído\")\n",
        "    df_results_B = pd.DataFrame(results_B)[['Indutor', 'Taxa de Acerto (%)', 'F1 (%)', 'Precisão (%)', 'Sensibilidade (%)', 'Especificidade (%)']]\n",
        "\n",
        "if df_reg is not None:\n",
        "    # --- Tabela C: Regressão com Hold-out ---\n",
        "    print(\"\\n--- Processando Tabela C: Regressão com Hold-out (65/35) ---\")\n",
        "    results_C = []\n",
        "    X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X_reg, y_reg, test_size=0.35, random_state=42)\n",
        "    for name, model in models_reg.items():\n",
        "        pipeline = Pipeline(steps=[('preprocessor', preprocessor_reg), ('regressor', model)])\n",
        "        pipeline.fit(X_train_r, y_train_r)\n",
        "        y_pred_r = pipeline.predict(X_test_r)\n",
        "        metrics = get_regression_metrics(y_test_r, y_pred_r)\n",
        "        metrics['Indutor'] = name\n",
        "        results_C.append(metrics)\n",
        "        print(f\"  - {name}: Concluído\")\n",
        "    df_results_C = pd.DataFrame(results_C)[['Indutor', 'Coeficiente de Determinação (R2)', 'MSE', 'RMSE', 'MAE']]\n",
        "\n",
        "    # --- Tabela D: Regressão com Validação Cruzada (5 folds) ---\n",
        "    print(\"\\n--- Processando Tabela D: Regressão com Validação Cruzada (5 folds) ---\")\n",
        "    results_D = []\n",
        "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    scoring_reg = ['r2', 'neg_mean_squared_error', 'neg_mean_absolute_error']\n",
        "    for name, model in models_reg.items():\n",
        "        pipeline = Pipeline(steps=[('preprocessor', preprocessor_reg), ('regressor', model)])\n",
        "        scores = cross_validate(pipeline, X_reg, y_reg, cv=kfold, scoring=scoring_reg)\n",
        "        results_D.append({\n",
        "            'Indutor': name,\n",
        "            'Coeficiente de Determinação (R2)': scores['test_r2'].mean(),\n",
        "            'MSE': -scores['test_neg_mean_squared_error'].mean(),\n",
        "            'RMSE': np.sqrt(-scores['test_neg_mean_squared_error'].mean()),\n",
        "            'MAE': -scores['test_neg_mean_absolute_error'].mean()\n",
        "        })\n",
        "        print(f\"  - {name}: Concluído\")\n",
        "    df_results_D = pd.DataFrame(results_D)[['Indutor', 'Coeficiente de Determinação (R2)', 'MSE', 'RMSE', 'MAE']]\n",
        "\n",
        "#\n",
        "# 6. EXIBIÇÃO DOS RESULTADOS\n",
        "#\n",
        "\n",
        "# Exibo todas as tabelas no formato exigido pelo enunciado\n",
        "# Comentário rápido: essas saídas correspondem às quatro tabelas pedidas no PDF\n",
        "\n",
        "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
        "print(\"\\n\\n\" + \"=\"*80)\n",
        "print(\"RESULTADOS FINAIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "if 'df_results_A' in locals():\n",
        "    print(\"\\n\\nTABELA A: Classificação com protocolo Hold-out (65% para treinamento e 35% para teste)\")\n",
        "    print(df_results_A.to_string(index=False))\n",
        "    print(\"\\n\\nTABELA B: Classificação com protocolo experimental validação cruzada com 5 folds\")\n",
        "    print(df_results_B.to_string(index=False))\n",
        "\n",
        "if 'df_results_C' in locals():\n",
        "    print(\"\\n\\nTABELA C: Regressão com protocolo Hold-out (65% para treinamento e 35% para teste)\")\n",
        "    print(df_results_C.to_string(index=False))\n",
        "    print(\"\\n\\nTABELA D: Regressão com protocolo experimental validação cruzada com 5 folds\")\n",
        "    print(df_results_D.to_string(index=False))\n"
      ]
    }
  ]
}